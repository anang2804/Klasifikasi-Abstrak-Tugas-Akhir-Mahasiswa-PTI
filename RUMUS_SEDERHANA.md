# ğŸ“ Ringkasan Rumus - Menu Klasifikasi (Versi Sederhana)

## ğŸ“‹ Tahapan Klasifikasi

Ketika Anda input abstrak dan klik **Klasifikasi**, sistem akan:

### 1ï¸âƒ£ **Text Preprocessing** ğŸ§¹

**Tujuan:** Membersihkan dan standarisasi teks

```
Input: "Penelitian ini mengembangkan Aplikasi Mobile Android"
â†“
Lowercase: "penelitian ini mengembangkan aplikasi mobile android"
â†“
Hapus stopword: "penelitian mengembangkan aplikasi mobile android"
â†“
Stemming: "teliti kembang aplikasi mobile android"
```

**Rumus Stemming:** Algoritma Nazief & Adriani (ECS)

- Hapus imbuhan: meng-, di-, -kan, -an, dll
- Contoh: "mengembangkan" â†’ "kembang"

---

### 2ï¸âƒ£ **TF-IDF Feature Extraction** ğŸ”¢

**Tujuan:** Konversi teks jadi angka yang bisa dihitung

#### ğŸ“ Rumus TF (Term Frequency):

```
TF(kata) = Berapa kali kata muncul di dokumen
```

**Contoh:**

- "sistem informasi sistem akademik"
- TF("sistem") = 2

#### ğŸ“ Rumus IDF (Inverse Document Frequency):

```
IDF(kata) = log((Total Dokumen + 1) / (Dokumen yang punya kata + 1)) + 1
```

**Contoh:**

- Total dokumen = 312
- Kata "jaringan" ada di 70 dokumen
- IDF("jaringan") = log((312+1)/(70+1)) + 1 = **1.686** âœ… (kata penting!)

- Kata "sistem" ada di 280 dokumen
- IDF("sistem") = log((312+1)/(280+1)) + 1 = **1.105** (kata umum)

**ğŸ’¡ Artinya:** Kata yang jarang muncul (seperti "jaringan") lebih penting untuk klasifikasi!

#### ğŸ“ Rumus TF-IDF:

```
TF-IDF = TF Ã— IDF
```

**Contoh:**

- Dokumen: "jaringan komputer jaringan wifi"
- TF("jaringan") = 2
- IDF("jaringan") = 1.686
- TF-IDF("jaringan") = 2 Ã— 1.686 = **3.372**

---

### 3ï¸âƒ£ **Cosine Similarity** ğŸ“

**Tujuan:** Ukur kesamaan antara abstrak Anda dengan 312 data training

#### ğŸ“ Rumus:

```
Similarity = (A Â· B) / (||A|| Ã— ||B||)

A = Vektor abstrak Anda
B = Vektor data training
A Â· B = Perkalian dot product
||A|| = Panjang vektor A
```

**Range:** 0 (tidak mirip) sampai 1 (identik)

**Contoh:**

```
Abstrak Anda:    [0.5, 0.3, 0.8, 0.2]
Data Training 1: [0.6, 0.4, 0.7, 0.1]

Dot Product: (0.5Ã—0.6) + (0.3Ã—0.4) + (0.8Ã—0.7) + (0.2Ã—0.1)
           = 0.30 + 0.12 + 0.56 + 0.02 = 1.00

||Anda|| = sqrt(0.5Â² + 0.3Â² + 0.8Â² + 0.2Â²) = 1.02
||Training1|| = sqrt(0.6Â² + 0.4Â² + 0.7Â² + 0.1Â²) = 1.06

Similarity = 1.00 / (1.02 Ã— 1.06) = 0.92 = 92% mirip! âœ…
```

---

### 4ï¸âƒ£ **K-Nearest Neighbor (k=5)** ğŸ¯

**Tujuan:** Cari 5 dokumen paling mirip, lalu voting!

#### Contoh Hasil:

```
Abstrak Anda: "aplikasi mobile android java mysql"

Top-5 Tetangga Terdekat:
1. 92% mirip â†’ RPL â†’ "aplikasi android java"
2. 88% mirip â†’ RPL â†’ "mobile apps java"
3. 85% mirip â†’ RPL â†’ "sistem informasi android"
4. 78% mirip â†’ TKJ â†’ "jaringan mobile wifi"
5. 76% mirip â†’ RPL â†’ "web application mysql"

Voting: RPL = 4 suara, TKJ = 1 suara
Hasil: RPL âœ…
```

---

### 5ï¸âƒ£ **Confidence Calculation** ğŸ²

**Tujuan:** Seberapa yakin sistem dengan prediksinya?

#### ğŸ“ Rumus:

```
Confidence = (Î£ Similarity untuk label terpilih) / (Î£ Semua similarity)
```

**Contoh:**

```
RPL: 0.92 + 0.88 + 0.85 + 0.76 = 3.41
TKJ: 0.78 = 0.78

Confidence = 3.41 / (3.41 + 0.78) = 0.814 = 81.4% âœ…
```

**Interpretasi:**

- âœ… **>80%**: Hasil sangat akurat!
- âš ï¸ **60-80%**: Hasil cukup akurat
- âŒ **<60%**: Hasil kurang pasti

---

## ğŸ¨ Visual Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: "Penelitian ini mengembangkan   â”‚
â”‚  aplikasi mobile Android untuk sistem   â”‚
â”‚  informasi akademik"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PREPROCESSING                          â”‚
â”‚  â†’ lowercase, clean, tokenize           â”‚
â”‚  â†’ stopword removal                     â”‚
â”‚  â†’ stemming (Sastrawi)                  â”‚
â”‚                                         â”‚
â”‚  Result: "teliti kembang aplikasi       â”‚
â”‚  mobile android sistem informasi..."    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TF-IDF VECTORIZATION                   â”‚
â”‚  â†’ TF(kata) = frekuensi                 â”‚
â”‚  â†’ IDF(kata) = log(N/df)                â”‚
â”‚  â†’ TF-IDF = TF Ã— IDF                    â”‚
â”‚                                         â”‚
â”‚  Result: [0.23, 0.19, 0.18, ... 0.00]  â”‚
â”‚          (1000 angka)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COSINE SIMILARITY                      â”‚
â”‚  â†’ Hitung dengan 312 data training      â”‚
â”‚  â†’ Similarity = cos(A,B)                â”‚
â”‚                                         â”‚
â”‚  Result: [0.92, 0.88, 0.85, ...]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K-NEAREST NEIGHBOR (k=5)               â”‚
â”‚  â†’ Ambil 5 terdekat                     â”‚
â”‚  â†’ Voting berbobot similarity           â”‚
â”‚                                         â”‚
â”‚  Result: RPL (4 votes) vs TKJ (1 vote) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT                                 â”‚
â”‚  âœ… Label: RPL                          â”‚
â”‚  âœ… Confidence: 81.4%                   â”‚
â”‚  âœ… Top Words: aplikasi, mobile,        â”‚
â”‚     android, sistem, informasi          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Contoh Sederhana

### Kasus 1: Abstrak RPL (Jelas)

```
Input: "Pengembangan aplikasi web e-commerce menggunakan
        Laravel dan MySQL dengan payment gateway Midtrans"

Top-5 Neighbors:
1. 94% â†’ RPL (laravel, web, aplikasi)
2. 91% â†’ RPL (e-commerce, payment)
3. 89% â†’ RPL (web application, mysql)
4. 87% â†’ RPL (sistem informasi, database)
5. 84% â†’ RPL (aplikasi berbasis web)

Result: RPL - Confidence: 91.2% âœ… TINGGI
```

### Kasus 2: Abstrak TKJ (Jelas)

```
Input: "Implementasi Virtual Private Network (VPN) dengan
        OpenVPN pada jaringan komputer untuk keamanan data"

Top-5 Neighbors:
1. 93% â†’ TKJ (vpn, jaringan, keamanan)
2. 90% â†’ TKJ (openvpn, network security)
3. 86% â†’ TKJ (jaringan komputer, protokol)
4. 82% â†’ TKJ (infrastruktur jaringan)
5. 79% â†’ TKJ (network configuration)

Result: TKJ - Confidence: 86.0% âœ… TINGGI
```

### Kasus 3: Abstrak Ambiguous (Mixed)

```
Input: "Sistem monitoring jaringan berbasis web untuk
        mengelola server dan database"

Top-5 Neighbors:
1. 82% â†’ TKJ (monitoring jaringan, server)
2. 79% â†’ RPL (sistem berbasis web)
3. 76% â†’ TKJ (network management)
4. 74% â†’ RPL (aplikasi web, database)
5. 71% â†’ TKJ (infrastruktur server)

Result: TKJ - Confidence: 65.4% âš ï¸ SEDANG
(Ada kata kunci dari kedua kelas)
```

---

## ğŸ“š Parameter yang Digunakan

### TF-IDF:

- `max_features`: 1000 kata
- `ngram_range`: (1,2) - unigram + bigram
- `min_df`: 2 - minimal muncul di 2 dokumen
- `max_df`: 0.8 - maksimal muncul di 80% dokumen
- `norm`: L2 normalization

### KNN:

- `n_neighbors`: 5 tetangga
- `metric`: cosine similarity
- `weights`: distance (voting berbobot)

### Data Training:

- Total: 312 abstrak (242 RPL, 70 TKJ)
- Sumber: ejournal.unesa.ac.id
- Labeling: Otomatis dengan keyword scoring

---

## â“ FAQ

**Q: Kenapa pakai Cosine Similarity, bukan Euclidean?**
A: Karena fokus ke arah/orientasi teks, bukan panjang dokumen.

**Q: Kenapa k=5?**
A: Berdasarkan eksperimen, k=5 memberikan akurasi terbaik (~85-90%).

**Q: Kenapa confidence kadang rendah?**
A: Abstrak mengandung kata kunci dari kedua kelas (RPL & TKJ).

**Q: Bagaimana cara meningkatkan akurasi?**
A: Tambah data training, terutama untuk kelas minority (TKJ).
